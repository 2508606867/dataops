关于如何解决20G数据的系统改进性思考。

# 存在的问题

+ 问题一：计算端不能够再使用简单的a+b=c的形式了
  + 一个20G的数据处理之后封装到数据里，那么原数据和刚处理完的新数据就是20+20=40G，以此类推
+ 问题二：大文件的传输不能够依赖于kafka，必须使用元数据的格式进行传递

# 解决思路

+ 解决思路：大文件如果传元数据的格式的话	

  + 数据处理之后结果的更新，应该是直接去元数据指向的结果集中添加结果，那么实现这些操作的必须条件就是计算端和数据文件都应该在一台机器上。（实际上整个java端都应该不用，只是现目前数据文件的上传应该改一下方式，上传到计算端的服务器上去）

    ​      文件上传方式改变、数据传输形式改变。

    + 计算端web服务开一个数据文件上传的接口，上传文件成功后返回文件元数据，前端保存文件元数据

    + 前端拼接完流程图后把文件元数据（这个地方的元数据就是一个数据文件保存的地址）一起上传

    + task封装模块负责封装task，（此时只是文件元数据作为数据而已，不用改太多or不需要改动）

    + 调度端（之前有计算端模块处理完成之后的参数更新），把参数更新模块删除，新添加一个模块，这个模块只是更新和维护元数据表、添加一个方法，这个方法是生成元数据表（taskhandle传过来的只是数据位置）。

    + 计算端拿到调用数据中的元数据之后去取出数据进行处理，处理完成之后对数据进行更新并返回元数据的一部分（处理完之后新数据的元数据）

      + 在更新操作里面的想法

        在文件上传的时候就使用**元数据（数据上传之后元数据指向的是一个json文件，这个json文件描述了数据的基本信息，比如数据的位置、数据的id、数据的版本号等等计算端根据数据id获取数据。）**的方式，进行计算以后计算端先通过元数据，根据里面的数据的id（desc）找到数据，对数据进行处理，处理完成之后另存为一个新的数据文件，并生成该数据的元数据信息保存到元数据json文件当中。这样一个json文件就保存了每一版本的数据（不用的后期也可以通过其他方式找到不用的数据，删除）. 元数据的格式如下。计算完成之后调用计算完成节点（新加的一个默认节点，这个节点就把原数据的location转化为下载的链接供用户下载，并且可以选择下载某一个步骤的数据之类的。

        ```json
        {
            "dataList": [
                {
                    "desc":"start desc",
                    "version":"0",
                    "location":"/Users/dailinfeng/Desktop/dataops/data/fe0d8598-add8-41da-9624-a04a77afb98a.csv",
                  	"hosts":[]
                },
                {
                    "desc":"start desc 2",
                    "version":"0",
                    "location":"/Users/dailinfeng/Desktop/dataops/data/fe0d8598-add8-41da-9624-a04a77afb98a.csv",
                  	"hosts":[]
                }
            ]
        }
        ```





##  

之前说的python的web部署的思路那些都可以不变，只是部署的时候需要映射一下文件夹而已



+ python端docker部署也没问题，n个容器都把镜像映射到同一个目录，这样的话是docker进行部署，可以横向扩张，并且能够共享同一个硬盘空间，这样的话一个task只需要在同一台主机上跑就可以了，因为他们的空间是共享的

  + **不一致问题的解决（修改数据不一致）** 

+ 后期一个流程图要放到几个主机跑的时候只是需要传递一下数据，最后的结果合并一下就可以（具体实现方法待定）

+ 

  

  

