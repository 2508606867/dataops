server:
  port: 18001
spring:
  application:
    name: taskhandle
  servlet:
    #上传文件大小限制  开大一点
    multipart:
      max-file-size: 99999999MB
      max-request-size: 99999999MB
  cloud:
    nacos:
      discovery:
        server-addr: 10.131.18.162:8848
  kafka:
    bootstrap-servers: 10.131.18.162:9092
    producer:
      key-serializer: org.apache.kafka.common.serialization.IntegerSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      #生产者每个批次最多放多少条记录
      batch-size: 16384
      #https://blog.csdn.net/u010711495/article/details/113250402
      #生产者一端总的可用发送缓冲区大小，此处可设置为32M
    #      buffer-memory: 1GB
    listener:
      ack-count: 1

taskKafkaTopic: topic-task-queue
data:
  save: /Users/dailinfeng/Desktop/dataops/result
  dataPath: /Users/dailinfeng/Desktop/dataops/data
  serverBaseUrl: http://127.0.0.1:8000/task

forest:
  max-connections: 1000 # 连接池最大连接数，默认值为500
  max-route-connections: 500 # 每个路由的最大连接数，默认值为500
  timeout: 900000 # 请求超时时间，单位为毫秒, 默认值为3000
  connect-timeout: 3000 # 连接超时时间，单位为毫秒, 默认值为2000
  retry-count: 1 # 请求失败后重试次数，默认为0次不重试
  logEnabled: true # 打开或关闭日志，默认为true
  log-request: true # 打开/关闭Forest请求日志（默认为 true）
  log-response-status: true # 打开/关闭Forest响应状态日志（默认为 true）
  log-response-content: true # 打开/关闭Forest响应内容日志（默认为 false）
  variables:
    baseUrl: http://127.0.0.1:8000
    notifyUrl: http://10.131.18.162:5700   #qq 机器人的url